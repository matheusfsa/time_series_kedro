{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f21828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 21:41:39,190 - kedro.framework.hooks.manager - INFO - Registered hooks from 1 installed plugin(s): kedro-mlflow-0.7.6\n",
      "2022-02-19 21:41:39,272 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
      "2022-02-19 21:41:39,312 - kedro.config.config - INFO - Config from path `/home/matheus/projects/time_series_kedro/conf/local` will override the following existing top-level config keys: fr_horizon, initial, models, n_jobs, sampling, stride, use_exog\n",
      "2022-02-19 21:41:39,315 - root - INFO - ** Kedro project time_series_kedro\n",
      "2022-02-19 21:41:39,316 - root - INFO - Defined global variable `context`, `session`, `catalog` and `pipelines`\n",
      "2022-02-19 21:41:39,333 - root - INFO - Registered line magic `run_viz`\n",
      "2022-02-19 21:41:39,334 - root - INFO - Registered line magic `reload_kedro_mlflow`\n",
      "2022-02-19 21:41:39,335 - kedro.io.data_catalog - INFO - Loading data from `train_data` (CSVDataSet)...\n",
      "2022-02-19 21:41:39,352 - kedro.io.data_catalog - INFO - Loading data from `eval_data` (CSVDataSet)...\n",
      "2022-02-19 21:41:39,356 - kedro.io.data_catalog - INFO - Loading data from `best_estimators` (CSVDataSet)...\n",
      "2022-02-19 21:41:39,408 - kedro.io.data_catalog - INFO - Loading data from `params:series_level.columns` (MemoryDataSet)...\n",
      "2022-02-19 21:41:39,411 - kedro.io.data_catalog - INFO - Loading data from `params:serie_target` (MemoryDataSet)...\n",
      "2022-02-19 21:41:39,413 - kedro.io.data_catalog - INFO - Loading data from `params:serie_period` (MemoryDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/.local/lib/python3.8/site-packages/kedro/io/core.py:151: DeprecatedWarning: __init__ is deprecated as of 0.7.3 and will be removed in 0.8.0. Deprecated in favor of 'MlflowMetricDataSet' (for a single metric) or 'MlflowMetricHistoryDataSet '(for the metric evolution over time)\n",
      "  data_set = class_obj(**config)  # type: ignore\n",
      "/home/matheus/.local/lib/python3.8/site-packages/kedro_mlflow/framework/hooks/pipeline_hook.py:53: DeprecatedWarning: __init__ is deprecated as of 0.7.3 and will be removed in 0.8.0. Deprecated in favor of 'MlflowMetricDataSet' (for a single metric) or 'MlflowMetricHistoryDataSet '(for the metric evolution over time)\n",
      "  catalog._data_sets[name] = MlflowMetricsDataSet(prefix=name)\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro\n",
    "train_data = catalog.load(\"train_data\")\n",
    "test_data = catalog.load(\"eval_data\")\n",
    "best_estimators = catalog.load(\"best_estimators\")\n",
    "serie_id = catalog.load(\"params:series_level.columns\")\n",
    "serie_target = catalog.load(\"params:serie_target\")\n",
    "date_col = catalog.load(\"params:serie_period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3e6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from xmlrpc.client import boolean\n",
    "\n",
    "import numpy as np\n",
    "from time_series_kedro.pipelines.training.nodes._params_search import build_params_search\n",
    "from time_series_kedro.pipelines.training.nodes._search import TSModelSearchCV\n",
    "from time_series_kedro.extras.utils import model_from_string\n",
    "from pmdarima.model_selection import RollingForecastCV\n",
    "from sklearn.base import clone, BaseEstimator\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import warnings\n",
    "\n",
    "def _search(\n",
    "    serie_data: pd.DataFrame,\n",
    "    estimator_base: BaseEstimator,\n",
    "    model_groups_params: Dict[str, Any],\n",
    "    serie_target: str,\n",
    "    date_col: str,\n",
    "    stride: int,\n",
    "    fr_horizon: int,\n",
    "    initial: Union[float, int],\n",
    "    n_jobs: int,\n",
    "    score: str,\n",
    "    use_exog: bool,\n",
    "    exog_columns: Optional[List[str]]):\n",
    "    \"\"\"\n",
    "    This node train and search the best estimators for a serie.\n",
    "    Args:\n",
    "        series_data: DataFrame with train time series.\n",
    "        serie_id: Column or list of columns that identify series.\n",
    "        serie_data: DataFrame with time series.\n",
    "        serie_target: Target column name.\n",
    "        date_col: Period column name.\n",
    "        model: Dict with model definition\n",
    "        stride: Stride of Cross Validation\n",
    "        fr_horizon: Forecast horizon of Cross Validation\n",
    "        initial: initial size of train dataset\n",
    "        n_jobs: number of jobs in Cross Validation process\n",
    "        score: used metric\n",
    "    Returns:\n",
    "        Best Estimator\n",
    "    \"\"\"\n",
    "\n",
    "    serie_group = serie_data.group.iloc[0]\n",
    "    \n",
    "    if serie_group in model_groups_params:\n",
    "        model_group  = serie_group\n",
    "    elif \"all\" in model_groups_params:\n",
    "        model_group = \"all\"\n",
    "    else:\n",
    "        model_group = None\n",
    "    if model_group is not None:\n",
    "        params_search = build_params_search(model_groups_params[model_group][\"params_search\"])\n",
    "        estimator = clone(estimator_base)\n",
    "        ts = serie_data.set_index(date_col)[serie_target]\n",
    "        start_point = int(initial) if initial > 1 else int(initial*ts.shape[0])\n",
    "        cv = RollingForecastCV(step=stride, h=fr_horizon, initial=start_point)\n",
    "        search = TSModelSearchCV(clone(estimator), params_search, cv_split=cv, n_jobs=n_jobs, verbose=0, score=score)\n",
    "        if use_exog:\n",
    "            X = serie_data[exog_columns + [date_col]].set_index(date_col) if len(exog_columns) else None\n",
    "        else:\n",
    "            X = None\n",
    "        search.fit(np.log1p(ts), X=X)\n",
    "        result = pd.Series({\"estimator\": search._best_estimator, \"metric\": search._best_score})\n",
    "        \n",
    "    else:\n",
    "        result = pd.Series({\"estimator\": None, \"metric\": np.nan})\n",
    "    return result   \n",
    "\n",
    "def model_selection(serie_id, *best_estimators):\n",
    "\n",
    "    estimators = pd.concat(best_estimators)\n",
    "    estimators = estimators.reset_index().groupby(serie_id).apply(lambda data: data.set_index(\"estimator\").metric.idxmin())\n",
    "    estimators.name = \"best_estimator\"\n",
    "    estimators = estimators.reset_index()\n",
    "    \n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37adf6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def train_model_apply(\n",
    "    series_data: pd.DataFrame,\n",
    "    serie_id: Union[str, List],\n",
    "    serie_target: str,\n",
    "    date_col: str,\n",
    "    model: Dict[str, Any],\n",
    "    stride: int,\n",
    "    fr_horizon: int,\n",
    "    initial: Union[float, int],\n",
    "    train_start: Optional[Dict],\n",
    "    use_exog: bool, \n",
    "    exog_info: Optional[Dict],\n",
    "    n_jobs: int = -1,\n",
    "    score: str = \"rmse\",\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This node train and search the best estimators for each serie.\n",
    "    Args:\n",
    "        series_data: DataFrame with train time series.\n",
    "        serie_id: Column or list of columns that identify series.\n",
    "        serie_data: DataFrame with time series.\n",
    "        serie_target: Target column name.\n",
    "        date_col: Period column name.\n",
    "        model: Dict with model definition\n",
    "        stride: Stride of Cross Validation\n",
    "        fr_horizon: Forecast horizon of Cross Validation\n",
    "        initial: initial size of train dataset\n",
    "        n_jobs: number of jobs in Cross Validation process\n",
    "        score: used metric\n",
    "    Returns:\n",
    "        Best Estimators for each serie\n",
    "    \"\"\"\n",
    "    if train_start is not None:\n",
    "        if train_start[\"by\"] ==  \"offset\":\n",
    "            train_start_date = series_data.date.max() - DateOffset(**train_start[\"date\"])\n",
    "        elif train_start[\"by\"] == \"date\":\n",
    "            train_start_date = train_start[\"date\"]\n",
    "        else:\n",
    "            raise ValueError(f\"Filter by {train_start['by']} was not implemented\")\n",
    "        series_data = series_data[series_data.date >= train_start_date]\n",
    "    model_groups_params = model[\"params\"]\n",
    "    exog_list = []\n",
    "    if exog_info is not None:\n",
    "        for exog_name in exog_info:\n",
    "            exog_list += exog_info[exog_name][\"target_columns\"]\n",
    "    \n",
    "    estimator = model_from_string(model[\"model_class\"], model[\"default_args\"])\n",
    "    best_estimators = series_data.groupby(serie_id).apply(lambda serie_data: _search(serie_data, \n",
    "                                                                                            estimator, \n",
    "                                                                                            model_groups_params, \n",
    "                                                                                            serie_target, \n",
    "                                                                                            date_col, \n",
    "                                                                                            stride, \n",
    "                                                                                            fr_horizon, \n",
    "                                                                                            initial,\n",
    "                                                                                            n_jobs,\n",
    "                                                                                            score,\n",
    "                                                                                            use_exog,\n",
    "                                                                                            exog_list))\n",
    "    return best_estimators\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d87f12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    series_data: pd.DataFrame,\n",
    "    serie_id: Union[str, List],\n",
    "    serie_target: str,\n",
    "    date_col: str,\n",
    "    model: Dict[str, Any],\n",
    "    stride: int,\n",
    "    fr_horizon: int,\n",
    "    initial: Union[float, int],\n",
    "    train_start: Optional[Dict],\n",
    "    use_exog: bool, \n",
    "    exog_info: Optional[Dict],\n",
    "    n_jobs: int = -1,\n",
    "    score: str = \"rmse\",\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This node train and search the best estimators for each serie.\n",
    "    Args:\n",
    "        series_data: DataFrame with train time series.\n",
    "        serie_id: Column or list of columns that identify series.\n",
    "        serie_data: DataFrame with time series.\n",
    "        serie_target: Target column name.\n",
    "        date_col: Period column name.\n",
    "        model: Dict with model definition\n",
    "        stride: Stride of Cross Validation\n",
    "        fr_horizon: Forecast horizon of Cross Validation\n",
    "        initial: initial size of train dataset\n",
    "        n_jobs: number of jobs in Cross Validation process\n",
    "        score: used metric\n",
    "    Returns:\n",
    "        Best Estimators for each serie\n",
    "    \"\"\"\n",
    "    if train_start is not None:\n",
    "        if train_start[\"by\"] ==  \"offset\":\n",
    "            train_start_date = series_data.date.max() - DateOffset(**train_start[\"date\"])\n",
    "        elif train_start[\"by\"] == \"date\":\n",
    "            train_start_date = train_start[\"date\"]\n",
    "        else:\n",
    "            raise ValueError(f\"Filter by {train_start['by']} was not implemented\")\n",
    "        series_data = series_data[series_data.date >= train_start_date]\n",
    "    model_groups_params = model[\"params\"]\n",
    "    exog_list = []\n",
    "    if exog_info is not None:\n",
    "        for exog_name in exog_info:\n",
    "            exog_list += exog_info[exog_name][\"target_columns\"]\n",
    "    \n",
    "    estimator = model_from_string(model[\"model_class\"], model[\"default_args\"])\n",
    "    best_estimators = pd.DataFrame()\n",
    "    for serie_idx, serie_data in series_data.groupby(serie_id):\n",
    "        serie_result = _search(serie_data, estimator, model_groups_params, \n",
    "                               serie_target, date_col, stride, \n",
    "                               fr_horizon, initial,n_jobs,score, \n",
    "                               use_exog, exog_list)\n",
    "        for id_col, id in zip(serie_id, serie_idx):\n",
    "            serie_result[id_col] = id\n",
    "        best_estimators = pd.concat((best_estimators, serie_result), ignore_index=True)\n",
    "    \n",
    "    return best_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38526843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 21:55:27,195 - kedro.io.data_catalog - INFO - Loading data from `train_data` (CSVDataSet)...\n",
      "2022-02-19 21:55:27,214 - kedro.io.data_catalog - INFO - Loading data from `params:series_level.columns` (MemoryDataSet)...\n",
      "2022-02-19 21:55:27,215 - kedro.io.data_catalog - INFO - Loading data from `params:serie_target` (MemoryDataSet)...\n",
      "2022-02-19 21:55:27,217 - kedro.io.data_catalog - INFO - Loading data from `params:serie_period` (MemoryDataSet)...\n",
      "2022-02-19 21:55:27,217 - kedro.io.data_catalog - INFO - Loading data from `params:models` (MemoryDataSet)...\n",
      "2022-02-19 21:55:27,218 - kedro.io.data_catalog - INFO - Loading data from `params:initial` (MemoryDataSet)...\n",
      "2022-02-19 21:55:27,219 - kedro.io.data_catalog - INFO - Loading data from `params:stride` (MemoryDataSet)...\n",
      "2022-02-19 21:55:27,221 - kedro.io.data_catalog - INFO - Loading data from `params:fr_horizon` (MemoryDataSet)...\n"
     ]
    }
   ],
   "source": [
    "train_data = catalog.load(\"train_data\")\n",
    "serie_id = catalog.load(\"params:series_level.columns\")\n",
    "serie_target = catalog.load(\"params:serie_target\")\n",
    "date_col = catalog.load(\"params:serie_period\")\n",
    "models = catalog.load(\"params:models\")\n",
    "initial = catalog.load(\"params:initial\")\n",
    "stride = catalog.load(\"params:stride\")\n",
    "fr_horizon = catalog.load(\"params:fr_horizon\")\n",
    "model = models[\"exponential_smoothing\"]\n",
    "n_jobs = 4\n",
    "score = \"rmsle\"\n",
    "exog_info = None\n",
    "train_start = None\n",
    "use_exog = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ebffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.44 s ± 42.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit best_estimators = train_model_for(train_data, serie_id, serie_target, \\\n",
    "                                  date_col, model, stride, fr_horizon, \\\n",
    "                                  initial, train_start, use_exog, exog_info, \\\n",
    "                                  n_jobs, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa24d8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5 s ± 204 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit best_estimators = train_model_apply(train_data, serie_id, serie_target, \\\n",
    "                                  date_col, model, stride, fr_horizon, \\\n",
    "                                  initial, train_start, use_exog, exog_info, \\\n",
    "                                  n_jobs, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da93304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series_kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
